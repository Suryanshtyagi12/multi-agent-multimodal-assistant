
# Multi-Agent Multimodal Enterprise RAG Assistant

A production-style **Multi-Agent, Multimodal Retrieval-Augmented Generation (RAG) system**
that can ingest **PDFs and images**, understand them using **text + vision models**, and
generate **grounded answers and enterprise outputs** such as summaries, emails, and bug reports.

This project demonstrates real-world **GenAI system design**, including persistent vector
databases, multimodal embeddings, OCR, agent orchestration, and an interactive chat UI.

---

## ğŸš€ Key Features

- **Multimodal RAG**: Query across PDFs, documents, screenshots, and diagrams  
- **Text + Image Retrieval**:
  - Text embeddings for PDFs
  - CLIP-based image embeddings for visual search
  - OCR (Tesseract) for extracting text from images
- **Multi-Agent Architecture**:
  - Router Agent (query classification)
  - RAG Agent (multimodal retrieval + reasoning)
  - Automation Agent (email, summary, bug report generation)
- **Persistent Vector Database**:
  - ChromaDB with disk persistence
- **Free LLM Integration**:
  - Groq LLaMA-3.1 (no paid API required)
- **Interactive Chat UI**:
  - Built with Streamlit
  - Upload files, ask questions, view evidence, trigger automations

---

## ğŸ§  System Architecture

User Query
â†“
Streamlit UI
â†“
Router Agent
â†“
Multimodal RAG Agent
â”œâ”€â”€ Text Retriever (PDFs)
â”œâ”€â”€ Image Retriever (CLIP + OCR)
â†“
LLM (Groq LLaMA-3.1)
â†“
Answer / Summary / Email / Bug Report


---

## ğŸ“‚ Project Structure

multi-agent-multimodal-assistant/
â”‚
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ ingestion/
â”‚ â”‚ â”œâ”€â”€ pdf_ingest.py
â”‚ â”‚ â”œâ”€â”€ image_ingest.py
â”‚ â”œâ”€â”€ retrievers/
â”‚ â”‚ â”œâ”€â”€ text_retriever.py
â”‚ â”‚ â”œâ”€â”€ image_retriever.py
â”‚ â”œâ”€â”€ agents/
â”‚ â”‚ â”œâ”€â”€ router_agent.py
â”‚ â”‚ â”œâ”€â”€ rag_agent.py
â”‚ â”‚ â”œâ”€â”€ automation_agent.py
â”‚ â”œâ”€â”€ ui/
â”‚ â”‚ â”œâ”€â”€ streamlit_app.py
â”‚
â”œâ”€â”€ chroma_db/ # Persistent vector store
â”œâ”€â”€ run_basic_rag.py
â”œâ”€â”€ run_image_test.py
â”œâ”€â”€ run_multimodal_rag_test.py
â”œâ”€â”€ test_text_retrieve.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md


---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
2ï¸âƒ£ Activate Virtual Environment
Windows (PowerShell):

venv\Scripts\activate
3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
4ï¸âƒ£ Set Environment Variables
Create a .env file in the project root:

GROQ_API_KEY=your_groq_api_key_here
Do NOT commit .env to GitHub.

â–¶ï¸ Running the Project
Ingest PDFs
python run_basic_rag.py
Ingest Images (OCR + CLIP)
python run_image_test.py
Test Text Retrieval
python test_text_retrieve.py
Run Multimodal RAG (CLI Test)
python run_multimodal_rag_test.py
ğŸ’¬ Run the Chatbot UI (Recommended)
streamlit run app/ui/streamlit_app.py
Then open the browser URL shown by Streamlit.

In the UI you can:
Upload PDFs and images

Ask questions in chat

See text + image evidence

Generate:

Email drafts

Executive summaries

Bug reports (JSON)



